{"title":"ML 正则化","uid":"31038f1c745d94422e3236cfc3b2ffbe","slug":"ML-正则化","date":"2024-08-03T06:40:12.000Z","updated":"2024-08-13T12:58:48.962Z","comments":true,"path":"api/articles/ML-正则化.json","keywords":null,"cover":[],"content":"<h2 id=\"正则化\"><a href=\"#正则化\" class=\"headerlink\" title=\"正则化\"></a>正则化</h2><p>在机器学习模型中，正则化通过在模型的损失函数中添加一个正则项来实现。这些惩罚项通常会限制模型的复杂度，使模型更加简单，从而更好地泛化到新数据。</p>\n<p>在代价函数中加入正则项，通过lambda的来平衡拟合程度和参数的大小，约大越容易出现过拟合的现象。</p>\n<p>引入正则项后的代价函数:</p>\n<p><img src=\"https://raw.githubusercontent.com/Myprefer/ImageHost/main/202408031351589.png\"></p>\n<p><strong>λ</strong> 为正则化参数</p>\n<ul>\n<li>如果 λ 很大，正则化项的影响就很大，模型参数会被压得很小，导致模型变得简单（比如变成一条平滑的线）</li>\n<li>如果 λ 很小，正则化项的影响就很小，模型参数可以自由调整，模型可能会变得复杂。</li>\n</ul>\n<h3 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h3><p>如果有很多参数，我们<strong>不清楚哪个参数是高阶项</strong>，即<strong>不知道惩罚哪个能获得更好拟合的结果</strong>，因此<strong>引入正则化项统一惩罚参数</strong>(正则化参数)以得到较为简单的函数</p>\n<p>统一惩罚能得到简单结果是因为，高阶项受到惩罚的效果会更强，反映在图像上就是使其影响变弱</p>\n<ul>\n<li>在线性回归中, 正则化使参数w每次都与一个小于1的数相乘, 使参数w在每次迭代中收缩一点</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/Myprefer/ImageHost/main/202408031457844.png\"></p>\n<p>可以直观的理解为，我们<strong>最小化损失函数</strong>就是<strong>求蓝圈+红圈的和的最小值</strong>，而这个值通在很多情况下是两个曲面相交的地方。</p>\n<h3 id=\"Dropout\"><a href=\"#Dropout\" class=\"headerlink\" title=\"Dropout\"></a>Dropout</h3><p>好的模型应该对输入数据的扰动更鲁棒, 使用丢弃法(dropout)在层之间加入噪音</p>\n<p>丢弃法对每个元素进行如下扰动<br><img src=\"https://raw.githubusercontent.com/Myprefer/ImageHost/main/202408132042456.png\"></p>\n<p>有p的概率置为0, 否则置为x&#x2F;(1-p)(保证期望仍为x), p为丢弃概率, 是控制模型复杂度的超参数</p>\n<p>通常将丢弃法作用在隐藏全连接层的输出上</p>\n<p><img src=\"https://raw.githubusercontent.com/Myprefer/ImageHost/main/202408132055420.png\"></p>\n","text":"正则化在机器学习模型中，正则化通过在模型的损失函数中添加一个正则项来实现。这些惩罚项通常会限制模型的复杂度，使模型更加简单，从而更好地泛化到新数据。 在代价函数...","permalink":"/post/ML-正则化","photos":[],"count_time":{"symbolsCount":610,"symbolsTime":"1 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%AD%A3%E5%88%99%E5%8C%96\"><span class=\"toc-text\">正则化</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">工作原理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Dropout\"><span class=\"toc-text\">Dropout</span></a></li></ol></li></ol>","author":{"name":"Myprefer","slug":"blog-author","avatar":"https://gravatar.com/avatar/d195051819ce742212020a79d768fb6c?size=256&cache=1710768150791","link":"https://github.com/Myprefer","description":"web security learner, ML learner","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"ML 神经网络","uid":"13909e268f0450d522608f992a88d1f0","slug":"ML-神经网络","date":"2024-08-03T08:43:22.000Z","updated":"2024-08-11T11:48:48.305Z","comments":true,"path":"api/articles/ML-神经网络.json","keywords":null,"cover":[],"text":"神经网络用于识别复杂模式和数据中的特征。是机器学习和深度学习中的基础工具，特别适用于处理图像、语音和文本等非结构化数据。 层（Layer）神经元按层组织，每一层...","permalink":"/post/ML-神经网络","photos":[],"count_time":{"symbolsCount":946,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"Myprefer","slug":"blog-author","avatar":"https://gravatar.com/avatar/d195051819ce742212020a79d768fb6c?size=256&cache=1710768150791","link":"https://github.com/Myprefer","description":"web security learner, ML learner","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"ML 逻辑回归","uid":"447078f3f8d7cc4fd3994e9733503dbf","slug":"ML-逻辑回归","date":"2024-08-02T13:24:59.000Z","updated":"2024-08-12T02:37:53.081Z","comments":true,"path":"api/articles/ML-逻辑回归.json","keywords":null,"cover":[],"text":"逻辑回归逻辑回归用来解决分类问题, 如样本标签值为0或1, 则线性回归输出的值不太符合实际, 有较大的误差 对上述数据使用逻辑回归模型(这里使用了sigmoid...","permalink":"/post/ML-逻辑回归","photos":[],"count_time":{"symbolsCount":638,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"Myprefer","slug":"blog-author","avatar":"https://gravatar.com/avatar/d195051819ce742212020a79d768fb6c?size=256&cache=1710768150791","link":"https://github.com/Myprefer","description":"web security learner, ML learner","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}